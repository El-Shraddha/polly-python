{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://polly.elucidata.io/manage/workspaces?action=open_polly_notebook&amp;source=github&amp;path=ElucidataInc%2Fpolly-python%2Fblob%2Fmain%2FDiscover%2Fsearch_across_all_omixatlas.ipynb&amp;kernel=elucidata%2FPython+3&amp;machine=medium\" target=\"_parent\"><img alt=\"Open in Polly\" src=\"https://elucidatainc.github.io/PublicAssets/open_polly.svg\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prototype polly-python Notebook with examples showing how to query data across all OmixAtlas\n",
        "\n",
        "For internal use only\n",
        "\n",
        "Instructions:\n",
        "1. Please run all code cells one by one.\n",
        "2. User is required to enter an SQL query to search for the required datasets.\n",
        "\n",
        "For any support or feedback, kindly reach out to either pawan.verma@elucidata.io or yogesh.lakhotia@elucidata.io\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# please do not modify\n",
        "from IPython.display import display_html\n",
        "def restartkernel() :\n",
        "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install polly-python and joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!sudo pip3 install polly-python joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script>Jupyter.notebook.kernel.restart()</script>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "restartkernel() #Pause for a few seconds before the kernel is refreshed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script type=\"text/javascript\"> Jupyter.notebook.kernel.execute(\"url = '\" + window.location + \"'\", {}, {}); </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# please do not modify\n",
        "from IPython.display import HTML\n",
        "HTML('''<script type=\"text/javascript\"> Jupyter.notebook.kernel.execute(\"url = '\" + window.location + \"'\", {}, {}); </script>''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from polly.omixatlas import OmixAtlas\n",
        "from polly.auth import Polly\n",
        "from joblib import Parallel, delayed\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authenticate your Polly session using the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "AUTH_TOKEN=(os.environ['POLLY_REFRESH_TOKEN']) # Obtain authentication tokens\n",
        "Polly.auth(AUTH_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "omixatlas = OmixAtlas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining functions for searching across all OA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_split(query):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns N SQL queries equal to the number of input indexes\n",
        "    \n",
        "    Extended description of function.\n",
        "    \n",
        "    Parameters:\n",
        "    query (str): input SQL query to search across any given omixatlases\n",
        "    \n",
        "    Returns:\n",
        "    q_list (list): list of SQL queries where each query queries on a single index only.\n",
        "    \n",
        "    \"\"\"\n",
        "    q_list = []\n",
        "    \n",
        "    query = query.replace(\"\\n\", \"\") #remove new line from query\n",
        "    \n",
        "    q_list = re.split('union', query, flags=re.IGNORECASE)\n",
        "    q_list = [q.strip() for q in q_list]\n",
        "    \n",
        "    return q_list\n",
        "\n",
        "def query_oa(query, version):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a table containing metadata for all results based on the input SQL query\n",
        "    \n",
        "    Extended description of function.\n",
        "    \n",
        "    Parameters: \n",
        "    query (string): list of input SQL queries where each query is used to query across a single omixatlas\n",
        "    version (string): The API version of data infra on which to query\n",
        "    \n",
        "    Returns:\n",
        "    all_df (dataframe): DataFrame containing metadata of the resulting data.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    all_df = omixatlas.query_metadata(query, query_api_version=version)\n",
        "    return all_df\n",
        "    \n",
        "\n",
        "def parallel_query(query_list, version):\n",
        "    \n",
        "    \"\"\"\n",
        "    Performs a parallel execution by dividing the task among multiple threads rather than multiple CPUs\n",
        "    \n",
        "    Extended description of function.\n",
        "    \n",
        "    Parameters: \n",
        "    query_list (list): list of input SQL queries where each query is used to search across a single omixatlas\n",
        "    version (string): The API version of data infra on which to query\n",
        "    \n",
        "    Returns:\n",
        "    df (dataframe): DataFrame containing dataset level metadata of the resulting datasets.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    final = []\n",
        "    result = Parallel(n_jobs=4, prefer=\"threads\")(delayed(query_oa)(query, version) for query in query_list)\n",
        "\n",
        "    for that_dict in result:\n",
        "        if isinstance(that_dict, pd.DataFrame):\n",
        "            final.append(that_dict)\n",
        "    \n",
        "    df = pd.concat(final)\n",
        "    return df\n",
        "\n",
        "def empty_df():\n",
        "\n",
        "    \"\"\"\n",
        "    Creates an empty dataframe with a message when no data is returned\n",
        "    \n",
        "    Extended description of function.\n",
        "    \n",
        "    Returns:\n",
        "    empty_df (dataframe): An empty dataframe with a message.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    empty_df = pd.DataFrame()\n",
        "    data = pd.DataFrame({\"Message\": \"No Data to show!\"}, index=[0])\n",
        "    empty_df = empty_df.append(data)\n",
        "    return empty_df\n",
        "\n",
        "def query_all_oa(sql, api_ver):\n",
        "\n",
        "    \"\"\"\n",
        "    Entry point for the cross omixatlas querying app.\n",
        "    \n",
        "    Extended description of function.\n",
        "    \n",
        "    Parameters: \n",
        "    sql (string): Input SQL query\n",
        "    api_ver (string): The API version of data infra on which to query\n",
        "    \n",
        "    Returns:\n",
        "    result_df (dataframe): DataFrame containing dataset level metadata of the resulting datasets.\n",
        "    status (string): String containing messages for the user\n",
        "    time_elapsed (string): Execution wall-time in seconds\n",
        "    \"\"\"\n",
        "    \n",
        "    start_time = time.time()\n",
        "    result_df = pd.DataFrame()\n",
        "    \n",
        "    if('union' in sql.lower()):\n",
        "        try:\n",
        "            query_list = query_split(sql)\n",
        "            result_df = parallel_query(query_list, api_ver)\n",
        "            if result_df.empty:\n",
        "                status = 'Query successful, No datasets were returned'\n",
        "                result_df = empty_df()\n",
        "            else:\n",
        "                status = 'Query Successful'\n",
        "                \n",
        "        except Exception as e:\n",
        "            status = repr(e)\n",
        "            result_df = empty_df()\n",
        "    else:\n",
        "        try:\n",
        "            result_df = query_oa(sql, api_ver)\n",
        "            if result_df.empty:\n",
        "                status = 'Query successful, No datasets were returned'\n",
        "                result_df = empty_df()\n",
        "            else:\n",
        "                status = 'Query Successful'\n",
        "                \n",
        "        except Exception as e:\n",
        "            status = repr(e)\n",
        "            result_df = empty_df()\n",
        "    \n",
        "    time_elapsed = str(\"Elapsed time = --- %s seconds ---\" % (time.time() - start_time))\n",
        "    return(result_df, status, time_elapsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = f\"\"\"SELECT dataset_id, description, disease, tissue FROM geo.datasets WHERE data_type = 'Transcriptomics'\n",
        "UNION SELECT dataset_id, description, disease, tissue FROM tcga.datasets WHERE data_type = 'Mutation'\"\"\"\n",
        "\n",
        "version = 'v2'\n",
        "\n",
        "result, status, wall_time = query_all_oa(query, version)\n",
        "\n",
        "print(wall_time)\n",
        "print(status)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}